<!DOCTYPE html>
<html>
<title>Daniel Monroe</title>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet"  href="styles.css">
<body>

<!-- Navbar (sit on top) -->
<div class="w3-top">
  <div class="w3-bar w3-white w3-wide w3-padding w3-card">
    <a class="w3-bar-item "> Daniel Monroe</a>
    <!-- Float links to the right. Hide them on small screens -->
    <div class="w3-right">
      <a href= "index.html" class="w3-bar-item w3-button">About</a>
      <a href="education.html" class="w3-bar-item w3-button">Education</a>
      <a href="projects.html" class="w3-bar-item w3-button active">Projects</a>
    </div>
  </div>
    </div>




<!-- Page content -->

  
  <div style="width:100%; padding-left: 5%; padding-right: 5%; padding-top: max(64px, 5%); padding-bottom: 1%; display: inline-block;" id="bio" >
  	
    <h1><b>Projects</b></h1>

    I've taken part in a lot of projects over the years, mostly relating to computer chess. Some of these follow.
    

    <h2><b>Lc0 Transformer Model Architect</b></h2>

    <div>
    <img src= "imgs/lc0maps.png" style="width: 30%; height: auto;" > 
    <img src= "imgs/lc0prog.png" style="width: 40%; height: auto;" > 
    <!-- <img src= "imgs/lc0logo.jpg" style="width: 20%; height: auto;" >  -->



    </div>

    <br>


    <p>

    Since 2022 I have been the principal member of the Leela Chess Zero development team working on the transformer models the engine uses to guide search. 
    My main contribution was a position encoding that enables models to play as if 2.5x larger with a ~15% latency bump. 
    The latest architecture iteration can at a scale of 190 million parameters produce a policy that is competitive with grandmasters.
    Modern GPUs can evaluate this model thousands of times per second, allowing the engine to <i>effectively emulate the strength of thousands of grandmasters</i>.
    A weaker feat in the same vein was achieved independently and concurrently in
    <a  href= "https://proceedings.neurips.cc/paper_files/paper/2024/hash/78f0db30c39c850de728c769f42fc903-Abstract-Conference.html" class ="w3-text-blue">a 2024 paper by DeepMind</a>
    with an agent that evaluates 
    a 270-million parameter model for each legal move. Our strongest model <b> outperforms DeepMind's with 30x less computation</b>.

    <br>
    Our architecture has also been the subject of a <a  href= "https://arxiv.org/abs/2406.00877" class ="w3-text-blue">NeurIPS article</a> and a <a  href= "https://arxiv.org/abs/2505.21552" class ="w3-text-blue">preprint</a>
    analyzing its emergent capability of lookahead.
    One of the most interesting discoveries was an attention head which transmits information from the "to" square of the player's predicted follow-up move to the "to" square of the player's next move.
    
    <br>

    Each of my testing runs took a week or two on an A100 GPU, and training of full models took on the order of months on a cluster of 8 A100s.
    All my work was in Tensorflow, and models were trained in the supervised setting on datasets of billions to tens of billions of positions
    generated by prior reinforcement learning runs.

    <br>

    Some of the improvements I made to search include uncertainty weighting, which was first proposed in Go and allows the engine to put more
    effort into positions the neural network reports uncertainty about, gaining 5 Elo;
    and a scheme for sometimes reusing evaluations for positions that differ only in the 50-move rule count, gaining around 10 Elo.

    Versions of Leela equipped with a Chessformer model and these search improvements <b> defeated the reigning champion, Stockfish, at the TCEC Cup 11 and TCEC Swiss 6 and 7 championships</b>.
    
    <br>
    
    See <a  href= "https://lczero.org/blog/2024/02/transformer-progress/" class ="w3-text-blue">
        my blog post</a> and <a  href= "https://arxiv.org/abs/2409.12272" class ="w3-text-blue">
        our preprint</a>.
    


    </p>

    <h2><b>Stockfish Developer</b></h2>

    <img src= "imgs/sflogo.png" style="width: 30%; height: auto;" > 



    <p>

    Since 2024 I have been involved in the development of Stockfish, which is widely considered the strongest chess engine in existence.
    As of July 2025, I have <a  href= "https://github.com/official-stockfish/Stockfish/commits?author=daniel-monroe" class ="w3-text-blue">
    commited to the official Stockfish repository 40 times</a>.
    Some of my favorite improvements, each of which gained Elo, follow:
    </p>


    <ol>
    <li>I implemented an algorithm in cupy to increase the "block sparsity" of Stockfish's neural network.
        The idea was to iteratively calculate the change in sparsity from swaps of neurons as a matrix multiplication between 0-1 matrices,
        which can be done rapidly on Turing and later Cuda devices. This was turned into a command-line utility by another contributor.
        The speedup varied from 0.9% to 2.5% depending on the system.
    </li>
    <li> I had a series of three Elo gainers in the "prior countermove bonus",
        which updates the scores of moves in our history tables when the opponent's move was strong enough that it pushed us below search bounds.
        My improvements included allowing the multipliers in the bonus to be fractional and thus tunable (another contributor ran the tune for me).
        This allowed me to make a term which increases the bonus if we initially underestimated the opponent's move gradually increase with that underestimation.
        I also implemented a variant of the prior countermove bonus for captures since Stockfish has separate history tables for quiet moves and captures.

    </li>
    <li>
        Stockfish has a feature called "late move reduction" where it does a search with a reduced depth for moves that it considers unlikely to be the best move.
        I implemented two heuristics adjusting the depth based on how the evaluation changes when the move is played.
    </li>

    <li>
        Stockfish will stop searching a position if it has searched the position before with a higher depth and the search would fail based on that result.
        If there is a best move stored, I tell the engine to look up the entry for the position after that move and make sure that evaluation would still trigger the cutoff.
    </li>

    <li>
        Stockfish has a series of "correction tables" it uses to keep track of the error in its previous evaluations. Using the fact that the magnitude of the correction
        roughly represents the uncertainty in the evaluation, I made it more difficult for the engine to prune positions that have a large correction.
    </li>


    </ol>


    <h2><b>Vdwnumbers.org Distributed Computing Project Lead</b></h2>

    <img src= "imgs/computerfarm.png" style="width: 30%; height: auto;"> 

    <p>

    In 2015 I created a distributed computing project in BOINC to calculate lower bounds for a combinatorial object called a van der Waerden number
    using on a construction based the discrete logarithm modulo a prime. This started out as a way to get acquainted with Unix and C++ and to combine the computing power
    of a few laptops into an interesting project, but the project soon grew to include over 500 users in 90 countries. We discovered around a dozen new bounds,
    leading to <a  href= "https://arxiv.org/abs/1603.03301" class ="w3-text-blue">a paper</a>.

    <br>

    The infrastructure basically consisted of a server running a MySQL database to communicate with clients running a 200-line C++ program through BOINC.
    The server assigned ranges of integers to clients, and the clients returned the minimum length of the
    longest arithmetic progression in a coloring corresponding to each prime in that range.
    Two clients validated each other's results and sent their results to the server, which updated the table of bounds in real time.

    <br>


    I revamped the project in high school to focus on the two-color case of the problem, which allowed packing bits and reducing the memory requirement by a factor of 8.
    This allowed pushing the upper limit of the primes checked from a billion to 4 billion.
    </p>

    <h2><b>Chess Engine Development Youtuber</b></h2>

    <img src= "imgs/youtube.png" style="width: 30%; height: auto;">

    <p>

    I recently noticed that there was a lot of interest in projects like Stockfish and Lc0, with videos about games between these engines garnering hundreds of thousands of views.
    However, there are plenty of misconceptions about how these engines work (I've even found some misconceptions in papers from DeepMind).
    I make videos about the development of these engines, with a focus on my work. The channel has 2.7 thousand subscribers and a hundred thousand views. 

    </p>

    

  </div>










</body>
</html>



